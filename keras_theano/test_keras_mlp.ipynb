{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7c9dc9b41ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/device_lib.pyc\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     39\u001b[0m   return [\n\u001b[1;32m     40\u001b[0m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   ]\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.pyc\u001b[0m in \u001b[0;36mlist_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m   1677\u001b[0m                                           status)\n\u001b[1;32m   1678\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/miniconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42112260/how-do-i-use-the-tensorboard-callback-of-keras\n",
    "# tensorboard\n",
    "# https://www.youtube.com/watch?v=lV09_8432VA\n",
    "# https://www.youtube.com/watch?v=BqgTU7_cBnk - stydy model\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 328us/step - loss: 0.7153 - acc: 0.4880\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.7036 - acc: 0.5050\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.7027 - acc: 0.5050\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6938 - acc: 0.5090\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.6968 - acc: 0.4840\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6972 - acc: 0.4990\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6997 - acc: 0.5060\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6940 - acc: 0.5050\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6948 - acc: 0.5030\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6950 - acc: 0.5430\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.7002 - acc: 0.4850\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6930 - acc: 0.5080\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.6966 - acc: 0.5120\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.6949 - acc: 0.5240\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6949 - acc: 0.5170\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.6918 - acc: 0.5160\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6919 - acc: 0.5130\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6941 - acc: 0.4920\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6930 - acc: 0.5110\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6921 - acc: 0.5160\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6950 - acc: 0.5070\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.6946 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.6942 - acc: 0.5310\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.6932 - acc: 0.5240\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.6927 - acc: 0.5160\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.6922 - acc: 0.5070\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.6919 - acc: 0.5290\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 0.6931 - acc: 0.5070\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.6936 - acc: 0.5040\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6896 - acc: 0.5220\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6920 - acc: 0.5090\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.6930 - acc: 0.4870\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6913 - acc: 0.5270\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6895 - acc: 0.5200\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.6913 - acc: 0.5100\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 0.6931 - acc: 0.5010\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.6929 - acc: 0.5210\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6919 - acc: 0.5130\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 0.6917 - acc: 0.5160\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6918 - acc: 0.5040\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.6899 - acc: 0.5360\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.6938 - acc: 0.5050\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6935 - acc: 0.5150\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6909 - acc: 0.5090\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6932 - acc: 0.5410\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.6907 - acc: 0.5160\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6904 - acc: 0.5220\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6917 - acc: 0.5160\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6934 - acc: 0.5040\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6919 - acc: 0.5130\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,873\n",
      "Trainable params: 1,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tensorboard\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='/Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "tbCallBack.set_model(model)\n",
    "\n",
    "# https://stackoverflow.com/questions/47877475/keras-tensorboard-plot-train-and-validation-scalars-in-a-same-figure/48393723\n",
    "\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "weights, biases = model.layers[0].get_weights()\n",
    "#tf.summary.histogram(\"weights\", W1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          epochs=50,\n",
    "          batch_size=128, callbacks=[TrainValTensorBoard(write_graph=False)])\n",
    "\n",
    "#plt.plot(history)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "\n",
    "# export model\n",
    "# https://keras.io/models/about-keras-models/\n",
    "print model.summary()\n",
    "#print model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf training\n",
    "# Training Performance: A userâ€™s guide to converge faster (TensorFlow Dev Summit 2018)\n",
    "\n",
    "# https://www.youtube.com/watch?v=eBbEDRsCmv4 - Hands-on TensorBoard (TensorFlow Dev Summit 2017)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
