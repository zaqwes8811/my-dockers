{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /mnt/d5/datasets_pa//train_samples/samples_ff128_neg_filtered\n",
      "pos: 162\n",
      "neg: 2735\n",
      "pos_aug: 1418\n",
      "main_ratio: 0.8\n",
      "input_dim: 128\n",
      "sz: 128\n",
      "F1:0.586 P:0.515 R:0.680\n",
      "F1:0.578 P:0.504 R:0.676\n",
      "F1:0.465 P:0.376 R:0.608\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "\n",
    "# https://stackoverflow.com/questions/42112260/how-do-i-use-the-tensorboard-callback-of-keras\n",
    "# tensorboard\n",
    "# https://www.youtube.com/watch?v=lV09_8432VA\n",
    "# https://www.youtube.com/watch?v=BqgTU7_cBnk - stydy model\n",
    "\n",
    "class TrainValTensorBoardF1(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', name=\"test\", **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, name)\n",
    "        super(TrainValTensorBoardF1, self).__init__(training_log_dir, **kwargs)\n",
    "        \n",
    "        self.val_writer = tf.summary.FileWriter(training_log_dir)\n",
    "        self.val_writer1 = tf.summary.FileWriter(training_log_dir)\n",
    "        #self.val_writer_train = tf.summary.FileWriter(training_log_dir)\n",
    "\n",
    "        \n",
    "    def dump(self, f1_score_train, f1_score_cv, f1_score_test, x):\n",
    "        \n",
    "        # https://github.com/tensorflow/tensorflow/issues/7089\n",
    "        \n",
    "        # first\n",
    "        from numpy import random\n",
    "        \n",
    "        summary = tf.Summary()\n",
    "        summary_value = summary.value.add()\n",
    "        summary_value.simple_value = f1_score_train\n",
    "        summary_value.tag = \"f1_score_train\"\n",
    "        self.val_writer.add_summary(summary, x)\n",
    "\n",
    "        # second\n",
    "        if 1:\n",
    "#             summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = f1_score_cv\n",
    "            summary_value.tag = \"f1_score_cv\"\n",
    "#             self.val_writer1.add_summary(summary, x)\n",
    "            \n",
    "        if 1:\n",
    "#             summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = f1_score_test\n",
    "            summary_value.tag = \"f1_score_test\"\n",
    "            self.val_writer.add_summary(summary, x)\n",
    "            \n",
    "#         write_op = summary.merge_all()\n",
    "      \n",
    "\n",
    "#         log_var = tf.Variable(0.0)\n",
    "#         tf.summary.scalar(\"loss\", log_var)\n",
    "\n",
    "        write_op = tf.summary.merge_all([f1_score_test, f1_score_train])\n",
    "\n",
    "        #session = tf.InteractiveSession()\n",
    "        #session.run(tf.global_variables_initializer())\n",
    "        session = tf.keras.backend.get_session()\n",
    "\n",
    "#         for i in range(100):\n",
    "#             # for writer 1\n",
    "#             summary = session.run(write_op, {log_var: random.rand()})\n",
    "#             self.writer_1.add_summary(summary, i)\n",
    "#             self.writer_1.flush()\n",
    "\n",
    "#             # for writer 2\n",
    "        summary = session.run(write_op, {log_var: random.rand()})\n",
    "        self.val_writer.add_summary(summary, x)\n",
    "#         self.writer_2.flush()\n",
    "        \n",
    "        self.val_writer.flush()\n",
    "#         self.val_writer1.flush()\n",
    "        \n",
    "    def end_it(self):\n",
    "        self.val_writer.close()\n",
    "#         self.val_writer1.close()\n",
    "\n",
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n",
    "        \n",
    "# FIXME: load our dataset\n",
    "# load images\n",
    "from roadmarks_pipelines import dataset_manager\n",
    "from roadmarks_pipelines.dataset_manager import to_keras_y\n",
    "\n",
    "path = '/train_samples/samples_ff128_neg_filtered'\n",
    "dataset_root = '/mnt/d5/datasets_pa/'\n",
    "    \n",
    "data = dataset_manager.get_all_train_data(path, dataset_root)\n",
    "#y, X, _ = dataset_manager.unpack_data(data)\n",
    "\n",
    "# Load and split\n",
    "size = len(data)\n",
    "main_ratio = 0.8\n",
    "print 'main_ratio:', main_ratio\n",
    "t0 = int(size * main_ratio)\n",
    "t1 = t0 + int(size * (1 - main_ratio) / 2)\n",
    "\n",
    "y_train, x_train, fns_train = dataset_manager.unpack_data(data[0:t0])\n",
    "y_cv, x_cv, fns_cv = dataset_manager.unpack_data(data[t0:t1])\n",
    "y_test, x_test, _ = dataset_manager.unpack_data(data[t1:])\n",
    "\n",
    "# conv\n",
    "y_train = to_keras_y(y_train)\n",
    "y_cv = to_keras_y(y_cv)\n",
    "y_test = to_keras_y(y_test)\n",
    "\n",
    "# FIXME: plain eval\n",
    "\n",
    "# F1 as metric\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras - seems bad idea for opt\n",
    "input_dim = x_train.shape[1]\n",
    "print \"input_dim:\", input_dim\n",
    "\n",
    "from roadmarks_pipelines.Classifiers import FirstNFeaturesScaler\n",
    "from roadmarks_pipelines.utils import F1_score_batched\n",
    "\n",
    "# norm.\n",
    "featrues_scaler = FirstNFeaturesScaler(input_dim)\n",
    "featrues_scaler = featrues_scaler.fit(x_train)\n",
    "\n",
    "# norm immid.\n",
    "x_cv = featrues_scaler.transform(np.copy(x_cv))\n",
    "x_test = featrues_scaler.transform(np.copy(x_test))\n",
    "x_train = featrues_scaler.transform(np.copy(x_train))  \n",
    "\n",
    "# params\n",
    "decision_thr = 0.5\n",
    "batch_size = 128\n",
    "\n",
    "y_train_size = len(y_train)\n",
    "\n",
    "key = 0\n",
    "\n",
    "if key == 0:\n",
    "    # Model\n",
    "    tvtb = TrainValTensorBoardF1(name='m'+str(int(time.time())))\n",
    "    for end_ptr in range(batch_size, y_train_size + batch_size * 2, batch_size * 2):\n",
    "        ep = np.clip(end_ptr, 0, y_train_size-1)\n",
    "\n",
    "        y_train_sample = np.copy(y_train[0:ep])\n",
    "        if np.sum(y_train_sample) == 0:\n",
    "            continue\n",
    "        x_train_sample = np.copy(x_train[0:ep])\n",
    "        \n",
    "        print 'sz:', len(x_train_sample)\n",
    "\n",
    "        # Build model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(8, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Fit model\n",
    "        history = model.fit(x_train_sample, y_train_sample,\n",
    "                  epochs=2,\n",
    "                  batch_size=batch_size, verbose=0)\n",
    "        #, callbacks=[TrainValTensorBoard(write_graph=False)], \n",
    "         #                   )\n",
    "\n",
    "        # Validation\n",
    "        y_pred_test = np.array(model.predict(x_test) > decision_thr, dtype=np.int)\n",
    "\n",
    "\n",
    "        # predict\n",
    "        y_pred_train = np.array(model.predict(x_train_sample) > decision_thr, dtype=np.int)\n",
    "        y_pred_cv = np.array(model.predict(x_cv) > decision_thr, dtype=np.int)\n",
    "\n",
    "        f1_score_train = F1_score_batched(y_pred_train.ravel(), y_orig=y_train_sample.ravel())\n",
    "        f1_score_cv = F1_score_batched(y_pred_cv.ravel(), y_orig=y_cv.ravel())\n",
    "        f1_score_test = F1_score_batched(y_pred_test.ravel(), y_orig=y_test.ravel())  \n",
    "\n",
    "        #f1_scores_train.append(f1_score_train)\n",
    "        #f1_scores_cv.append(f1_score_cv)\n",
    "        #x_axis.append(ep)\n",
    "        \n",
    "        tvtb.dump(f1_score_train, f1_score_cv, f1_score_test, ep)\n",
    "        break\n",
    "\n",
    "    tvtb.end_it()\n",
    "    \n",
    "elif key == 2:\n",
    "    # https://www.kaggle.com/eikedehling/keras-nn-scaling-feature-selection-0-548\n",
    "    pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
